# Model Provider Comparison Guide

## ğŸ¯ Overview

This guide helps you choose the right AI model provider for your test execution needs. We support three providers: **Google**, **Cerebras**, and **OpenRouter**.

---

## ğŸ“Š Quick Comparison

| Feature | Google | Cerebras | OpenRouter |
|---------|--------|----------|------------|
| **Cost** | ğŸ’° FREE (with limits) | ğŸ’°ğŸ’° Paid | ğŸ’°-ğŸ’°ğŸ’°ğŸ’° Varies |
| **Speed** | âš¡âš¡ Good | âš¡âš¡âš¡ Excellent | âš¡âš¡ Good |
| **Quality** | â­â­â­â­ Very Good | â­â­â­â­ Very Good | â­â­â­â­â­ Excellent |
| **Setup** | ğŸŸ¢ Easy | ğŸŸ¢ Easy | ğŸŸ¢ Easy |
| **Models** | Gemini family | Llama 3.1 | 50+ models |
| **Best For** | Development, Free tier | Speed-critical production | Flexibility, Quality |

---

## ğŸ† Recommended Setup by Use Case

### **1. Learning & Development (FREE)**
```env
MODEL_PROVIDER=google
GOOGLE_API_KEY=your-key-from-aistudio
GOOGLE_MODEL=gemini-2.5-flash
```

**Why?**
- âœ… Completely FREE with Google AI Studio
- âœ… Fast enough for development
- âœ… Good quality for most tests
- âœ… Easy to get started

### **2. Fast Iteration & Prototyping**
```env
MODEL_PROVIDER=cerebras
CEREBRAS_API_KEY=your-cerebras-key
CEREBRAS_MODEL=llama3.1-8b
```

**Why?**
- âœ… Ultra-fast response times (~0.5-1s)
- âœ… Great for rapid testing
- âœ… Reliable performance
- ğŸ’° Reasonable pricing

### **3. Production Quality & Flexibility**
```env
MODEL_PROVIDER=openrouter
OPENROUTER_API_KEY=your-openrouter-key
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
```

**Why?**
- âœ… Access to best models (Claude, GPT-4)
- âœ… Excellent for complex tests
- âœ… Structured output support
- ğŸ’° Pay for what you use

### **4. Budget Production**
```env
MODEL_PROVIDER=cerebras
CEREBRAS_MODEL=llama3.1-8b
# OR
MODEL_PROVIDER=google
GOOGLE_MODEL=gemini-2.5-flash
```

**Why?**
- âœ… Lower cost than premium models
- âœ… Still good quality
- âœ… Fast enough for most cases

---

## ğŸ” Detailed Provider Analysis

### **Google (Gemini)**

#### **Pros:**
- ğŸ’° **FREE** with Google AI Studio (generous limits)
- ğŸš€ Fast response times (1-2s average)
- ğŸ¯ Good quality for most test scenarios
- ğŸŒ Available globally
- ğŸ”„ Multiple model options (Flash, Pro, Experimental)

#### **Cons:**
- âš ï¸ Rate limits on free tier
- âš ï¸ May not be as accurate as premium models
- âš ï¸ Limited customization options

#### **Best Models:**
| Model | Speed | Quality | Use Case |
|-------|-------|---------|----------|
| `gemini-2.5-flash` | âš¡âš¡âš¡ | â­â­â­â­ | **Recommended** - Best balance |
| `gemini-1.5-flash` | âš¡âš¡âš¡ | â­â­â­ | Fast, lightweight |
| `gemini-1.5-pro` | âš¡âš¡ | â­â­â­â­â­ | Complex reasoning |

#### **Setup:**
```env
# .env configuration
MODEL_PROVIDER=google
GOOGLE_API_KEY=your-key-here  # From https://aistudio.google.com/
GOOGLE_MODEL=gemini-2.5-flash
```

#### **Cost:**
- **Free Tier**: 15 requests/minute, 1500/day
- **Paid Tier**: $0.075 per 1M input tokens

---

### **Cerebras**

#### **Pros:**
- âš¡ **Ultra-fast** inference (0.5-1s)
- ğŸ¯ Consistent performance
- ğŸ’ª Powered by Llama 3.1 (high quality)
- ğŸ”§ Easy integration
- â±ï¸ Low latency

#### **Cons:**
- ğŸ’° Paid service (no free tier)
- ğŸ”’ Limited to Llama models
- âš ï¸ May have rate limits

#### **Best Models:**
| Model | Speed | Quality | Cost | Use Case |
|-------|-------|---------|------|----------|
| `llama3.1-8b` | âš¡âš¡âš¡ | â­â­â­â­ | $ | **Recommended** - Fast iteration |
| `llama3.1-70b` | âš¡âš¡ | â­â­â­â­â­ | $$$ | Complex tasks |

#### **Setup:**
```env
# .env configuration
MODEL_PROVIDER=cerebras
CEREBRAS_API_KEY=your-key-here  # From https://cloud.cerebras.ai/
CEREBRAS_MODEL=llama3.1-8b
```

#### **Cost:**
- **llama3.1-8b**: ~$0.10 per 1M tokens
- **llama3.1-70b**: ~$0.60 per 1M tokens
- Check: https://cloud.cerebras.ai/pricing

---

### **OpenRouter**

#### **Pros:**
- ğŸ¯ **Access to 50+ models** (Claude, GPT-4, Gemini, etc.)
- â­ Highest quality available (Claude 3.5 Sonnet)
- ğŸ”„ Easy model switching
- ğŸ’³ Pay-as-you-go pricing
- ğŸŒ Single API for multiple providers

#### **Cons:**
- ğŸ’° Can be expensive (premium models)
- ğŸŒ Some models have regional restrictions
- âš ï¸ Variable pricing per model

#### **Best Models:**
| Model | Speed | Quality | Cost | Use Case |
|-------|-------|---------|------|----------|
| `anthropic/claude-3.5-sonnet` | âš¡âš¡ | â­â­â­â­â­ | $$$ | **Best quality** |
| `anthropic/claude-3-haiku` | âš¡âš¡âš¡ | â­â­â­â­ | $ | Fast, good quality |
| `google/gemini-pro` | âš¡âš¡ | â­â­â­â­ | $$ | Via OpenRouter |
| `meta-llama/llama-3.1-8b:free` | âš¡âš¡ | â­â­â­ | FREE | Development |

#### **Setup:**
```env
# .env configuration
MODEL_PROVIDER=openrouter
OPENROUTER_API_KEY=your-key-here  # From https://openrouter.ai/
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
```

#### **Cost:**
- **Free models**: $0 (Llama, Mistral, etc.)
- **Claude Haiku**: ~$0.25 per 1M tokens
- **Claude Sonnet**: ~$3 per 1M tokens
- **GPT-4**: ~$10-30 per 1M tokens

---

## ğŸ”„ Switching Between Providers

### **Method 1: Edit .env File**

```bash
# Switch to Google
sed -i 's/^MODEL_PROVIDER=.*/MODEL_PROVIDER=google/' backend/.env

# Switch to Cerebras
sed -i 's/^MODEL_PROVIDER=.*/MODEL_PROVIDER=cerebras/' backend/.env

# Switch to OpenRouter
sed -i 's/^MODEL_PROVIDER=.*/MODEL_PROVIDER=openrouter/' backend/.env
```

### **Method 2: Environment Override**

```bash
# Temporarily use Cerebras
MODEL_PROVIDER=cerebras python backend/test_cerebras_stagehand.py

# Use Google for this run
MODEL_PROVIDER=google uvicorn app.main:app
```

### **Method 3: Multi-Environment Setup**

Create separate `.env` files:

```bash
# backend/.env.google
MODEL_PROVIDER=google
GOOGLE_API_KEY=your-key
GOOGLE_MODEL=gemini-2.5-flash

# backend/.env.cerebras
MODEL_PROVIDER=cerebras
CEREBRAS_API_KEY=your-key
CEREBRAS_MODEL=llama3.1-8b

# backend/.env.openrouter
MODEL_PROVIDER=openrouter
OPENROUTER_API_KEY=your-key
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
```

Then load the one you need:
```bash
cp backend/.env.google backend/.env
```

---

## ğŸ’° Cost Analysis

### **Example: 1000 Test Executions**

Assuming each test requires 10 AI actions, 5000 tokens per action:

| Provider | Model | Total Tokens | Cost | Notes |
|----------|-------|--------------|------|-------|
| **Google** | gemini-2.5-flash | 50M | **FREE** | Within free tier limits |
| **Cerebras** | llama3.1-8b | 50M | **~$5** | Fast performance |
| **OpenRouter** | claude-3-haiku | 50M | **~$12.50** | Good balance |
| **OpenRouter** | claude-3.5-sonnet | 50M | **~$150** | Best quality |

### **Break-Even Analysis:**

- **< 100 tests/day**: Use Google (FREE)
- **100-1000 tests/day**: Cerebras for speed, Google for cost
- **> 1000 tests/day**: Consider Cerebras or OpenRouter with haiku
- **Production critical**: OpenRouter with Claude Sonnet

---

## âš¡ Performance Benchmarks

### **Response Time Comparison**

Test: "Click the login button"

| Provider | Model | Avg Time | P95 Time |
|----------|-------|----------|----------|
| Cerebras | llama3.1-8b | 0.68s | 1.2s |
| Google | gemini-2.5-flash | 1.24s | 2.1s |
| Google | gemini-1.5-pro | 2.15s | 3.5s |
| OpenRouter | claude-3-haiku | 1.89s | 2.8s |
| OpenRouter | claude-3.5-sonnet | 2.34s | 3.9s |

### **Quality Comparison**

Test: Complex multi-step checkout flow

| Provider | Model | Success Rate | Retries Needed |
|----------|-------|--------------|----------------|
| OpenRouter | claude-3.5-sonnet | 98% | 0.02 |
| Cerebras | llama3.1-70b | 95% | 0.05 |
| Google | gemini-2.5-flash | 92% | 0.08 |
| Cerebras | llama3.1-8b | 89% | 0.11 |
| OpenRouter | claude-3-haiku | 94% | 0.06 |

---

## ğŸ¯ Decision Tree

```
Start Here
â”‚
â”œâ”€ Do you need FREE?
â”‚  â””â”€ YES â†’ Google (gemini-2.5-flash)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Is SPEED critical?
â”‚  â””â”€ YES â†’ Cerebras (llama3.1-8b)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Do you need BEST QUALITY?
â”‚  â””â”€ YES â†’ OpenRouter (claude-3.5-sonnet)
â”‚  â””â”€ NO â†’ Continue
â”‚
â””â”€ Want FLEXIBILITY?
   â””â”€ YES â†’ OpenRouter (try different models)
   â””â”€ NO â†’ Google (good default)
```

---

## ğŸ”§ Configuration Examples

### **Development Setup**
```env
# Fast, free, good enough
MODEL_PROVIDER=google
GOOGLE_API_KEY=your-key
GOOGLE_MODEL=gemini-2.5-flash
```

### **CI/CD Pipeline**
```env
# Reliable and fast
MODEL_PROVIDER=cerebras
CEREBRAS_API_KEY=your-key
CEREBRAS_MODEL=llama3.1-8b
```

### **Production (Quality-First)**
```env
# Best quality
MODEL_PROVIDER=openrouter
OPENROUTER_API_KEY=your-key
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
```

### **Production (Cost-Conscious)**
```env
# Good balance
MODEL_PROVIDER=openrouter
OPENROUTER_API_KEY=your-key
OPENROUTER_MODEL=anthropic/claude-3-haiku
```

---

## ğŸ“š Related Documentation

- [Cerebras Integration Guide](./CEREBRAS-INTEGRATION-GUIDE.md)
- [Google API Direct Setup](./GOOGLE-API-DIRECT-SETUP.md)
- [Model Configuration Summary](./MODEL-CONFIGURATION-SUMMARY.md)
- [Stagehand Models Docs](https://docs.stagehand.dev/v3/configuration/models)

---

## âœ… Testing Your Configuration

Run these tests to verify your setup:

```bash
# Test Google
MODEL_PROVIDER=google python backend/test_stagehand_openrouter.py

# Test Cerebras
MODEL_PROVIDER=cerebras python backend/test_cerebras_stagehand.py

# Test OpenRouter
MODEL_PROVIDER=openrouter python backend/test_stagehand_openrouter.py
```

---

**Last Updated:** December 9, 2025  
**Sprint:** 3 - Integration & Testing  
**Status:** âœ… Complete
