# ============================================
# AI Web Test Backend - Environment Variables
# ============================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to git!

# ============================================
# Database Configuration
# ============================================
# For local development (SQLite)
DATABASE_URL=sqlite:///./aiwebtest.db

# For production (PostgreSQL via Docker)
# DATABASE_URL=postgresql://postgres:postgres@localhost:5432/aiwebtest

# ============================================
# Security & Authentication
# ============================================
# Generate a secure secret key:
# python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-super-secret-key-change-this-in-production

# JWT Configuration
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# ============================================
# CORS Configuration
# ============================================
# Comma-separated list of allowed origins
# BACKEND_CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# ============================================
# OpenRouter API Configuration (Sprint 2)
# ============================================
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-api-key-here

# ============================================
# Google AI Studio Configuration (Direct)
# ============================================
# Get your API key from: https://aistudio.google.com/app/apikey
# This bypasses OpenRouter and uses Google API directly (FREE!)
# GOOGLE_API_KEY=your-google-api-key-here

# ============================================
# Cerebras Configuration (Fast Inference)
# ============================================
# Get your API key from: https://cloud.cerebras.ai/
# Cerebras provides ultra-fast inference with their custom hardware
# CEREBRAS_API_KEY=your-cerebras-api-key-here

# ============================================
# Model Provider Selection
# ============================================
# Choose which provider to use for test execution
# Options: "openrouter", "google", "cerebras"
# Default: "openrouter"
MODEL_PROVIDER=openrouter

# Legacy flags (still supported for backward compatibility)
# USE_GOOGLE_DIRECT=false
# USE_CEREBRAS=false

# ============================================
# Model Selection
# ============================================
# Choose your preferred LLM model from your selected provider
# 
# FOR GOOGLE (MODEL_PROVIDER=google or USE_GOOGLE_DIRECT=true):
# ------------------------------------------
GOOGLE_MODEL=gemini-1.5-flash
# Available models: 
#   - gemini-1.5-flash (fast, cost-effective)
#   - gemini-1.5-pro (higher quality)
#   - gemini-2.0-flash-exp (experimental)
#   - gemini-2.5-flash (latest, recommended)
#
# FOR CEREBRAS (MODEL_PROVIDER=cerebras or USE_CEREBRAS=true):
# ------------------------------------------
CEREBRAS_MODEL=llama3.1-8b
# Available models:
#   - llama3.1-8b (fast, good for most tasks)
#   - llama3.1-70b (higher quality, slower)
#
# FOR OPENROUTER (MODEL_PROVIDER=openrouter - default):
# ------------------------------------------
OPENROUTER_MODEL=mistralai/mixtral-8x7b-instruct

# OTHER FREE OPTIONS:
# -------------------
# DeepSeek Chat - Fast, good quality
# OPENROUTER_MODEL=deepseek/deepseek-chat
#
# Mistral 7B - Smaller, faster
# OPENROUTER_MODEL=mistralai/mistral-7b-instruct:free
#
# Meta Llama 3.2 3B - Very fast, smaller
# OPENROUTER_MODEL=meta-llama/llama-3.2-3b-instruct:free
#
# PAID PREMIUM MODELS (Better quality, costs money):
# ---------------------------------------------------
# Claude 3.5 Sonnet - Excellent for structured output (~$3/M tokens)
# OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
#
# Claude 3 Haiku - Fast and cheap (~$0.25/M tokens)
# OPENROUTER_MODEL=anthropic/claude-3-haiku
#
# GPT-4 Turbo - OpenAI's flagship (if available in your region)
# OPENROUTER_MODEL=openai/gpt-4-turbo
#
# GPT-3.5 Turbo - Cheaper, faster (~$0.50/M tokens)
# OPENROUTER_MODEL=openai/gpt-3.5-turbo
#
# Claude 3 Haiku - Fast and cheap (~$0.25/M tokens)
# OPENROUTER_MODEL=anthropic/claude-3-haiku
#
# Gemini Pro - Google's model
# OPENROUTER_MODEL=google/gemini-pro
#
# See all models: https://openrouter.ai/models
#
# NOTE: Free models on OpenRouter may have limited availability.
# We recommend using Claude 3.5 Sonnet or Claude 3 Haiku for reliable service.

# ============================================
# Model Selection Guide
# ============================================
#
# RECOMMENDED FOR DEVELOPMENT (FREE):
# - mistralai/mixtral-8x7b-instruct: Best free model
#   * Excellent quality for test generation
#   * Fast (6-7 seconds per request)
#   * Detailed, structured responses
#   * FREE (no cost!)
#
# OTHER FREE OPTIONS:
# - deepseek/deepseek-chat: Good quality, fast
# - mistralai/mistral-7b-instruct:free: Smaller, faster
# - meta-llama/llama-3.2-3b-instruct:free: Very fast
#
# RECOMMENDED FOR PRODUCTION (PAID):
# - anthropic/claude-3.5-sonnet: Best for structured output
#   * Excellent quality (~$9 per 1000 tests)
#   * Works globally
# - anthropic/claude-3-haiku: Fast, cheap
#   * Good quality (~$0.75 per 1000 tests)
#
# REGIONAL RESTRICTIONS:
# - OpenAI models (GPT-4, GPT-3.5) may not work in all regions
# - Claude models work globally
# - Free open-source models work everywhere
#
# COST CONSIDERATIONS:
# - Free models: $0 (Mixtral, DeepSeek, Mistral, Llama)
# - Claude Haiku: ~$0.75 per 1000 tests
# - Claude Sonnet: ~$9 per 1000 tests
# - GPT-4: ~$20 per 1000 tests

# ============================================
# API Configuration
# ============================================
API_V1_STR=/api/v1
PROJECT_NAME=AI Web Test

# ============================================
# Development Settings
# ============================================
# Set to true for debug logging
# DEBUG=true
